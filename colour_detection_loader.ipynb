{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.contrib.metrics import f1_score as ms\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train_colour_non_6jun_300.npy')\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "train_std = np.std(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-3a03eee2f665>:33: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-3a03eee2f665>:41: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n",
    "\n",
    "def weight_variable(layer_name,shape):\n",
    "    return tf.get_variable(layer_name,shape=shape,initializer=tf.contrib.layers.xavier_initializer(seed=1234),regularizer=regularizer)\n",
    "\n",
    "def bias_variable(layer_name,shape):\n",
    "    return tf.Variable(tf.zeros(shape=shape),name=layer_name)\n",
    "\n",
    "def conv_layer(inp, \n",
    "               layer_name_bias, \n",
    "               layer_name, \n",
    "               num_input_channels, \n",
    "               filter_size, \n",
    "               num_filters, \n",
    "               strides,\n",
    "               ksize_maxpool, \n",
    "               kernel_regularizer=regularizer,\n",
    "               pooling=True, \n",
    "               batchnorm=True, \n",
    "               dropout=True, \n",
    "               keep_prob=0.25):\n",
    "    \n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    weights = weight_variable(layer_name, shape=shape)\n",
    "    biases = bias_variable(layer_name_bias,shape=[num_filters])\n",
    "    layer = tf.nn.conv2d(input=inp, filter=weights, strides=[1,strides,strides,1], padding=\"SAME\")\n",
    "    \n",
    "    layer= tf.nn.bias_add(layer,biases)\n",
    "    \n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    if batchnorm:\n",
    "        layer = tf.layers.batch_normalization(layer)\n",
    "    \n",
    "    if pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1,ksize_maxpool,ksize_maxpool,1],\n",
    "                               strides=[1,ksize_maxpool,ksize_maxpool,1],\n",
    "                               padding='SAME')\n",
    "    if dropout: \n",
    "        layer = tf.layers.dropout(layer, keep_prob)\n",
    "        \n",
    "    return layer, weights\n",
    "\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    num_feat = np.prod(layer.get_shape().as_list()[1:4])\n",
    "    layer = tf.contrib.layers.flatten(layer)\n",
    "    \n",
    "    return layer, num_feat\n",
    "\n",
    "\n",
    "def fc_layer(input,\n",
    "             layer_name_bias,\n",
    "             layer_name,\n",
    "             num_in,\n",
    "             num_out,\n",
    "             relu=True,\n",
    "             batchnorm=True, \n",
    "             dropout=True, \n",
    "             keep_prob=0.5):\n",
    "    \n",
    "    weights = weight_variable(layer_name,shape=[num_in, num_out])\n",
    "    biases = bias_variable(layer_name_bias,shape=[num_out])\n",
    "    \n",
    "    result = tf.add(tf.matmul(input,weights),biases)\n",
    "    \n",
    "    if relu:\n",
    "        result = tf.nn.relu(result)\n",
    "    \n",
    "    if batchnorm:\n",
    "        result = tf.layers.batch_normalization(result)\n",
    "        \n",
    "    if dropout: \n",
    "        result = tf.layers.dropout(result, keep_prob)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def softmax_function(input,num_in,num_out,weight_name):\n",
    "    weights = weight_variable(weight_name,shape=[num_in, num_out])\n",
    "    biases = bias_variable(shape=[num_out])\n",
    "    result = tf.matmul(input,weights)+biases\n",
    "    \n",
    "    return result, weights\n",
    "\n",
    "\n",
    "def global_pooling(layer,global_pooling='mean'):\n",
    "    if global_pooling == 'mean':\n",
    "        tf.reduce_mean(layer, [1, 2], name='global_pool', keep_dims=True)\n",
    "    elif global_pooling == 'max':\n",
    "        tf.reduce_max(layer, [1, 2], name='global_pool', keep_dims=True)\n",
    "\n",
    "img_h = X_train.shape[1]\n",
    "img_w = X_train.shape[2]\n",
    "\n",
    "num_training_data = X_train.shape[0]\n",
    "num_labels=2\n",
    "\n",
    "# Number of channels: 1 because greyscale\n",
    "num_channels = 1\n",
    "\n",
    "filter_size1 = 5\n",
    "num_filters1 = 30\n",
    "strides1 = 2\n",
    "ksize_maxpool1 = 2\n",
    "\n",
    "filter_size2 = 3\n",
    "num_filters2 = 40\n",
    "strides2 = 1\n",
    "ksize_maxpool2 = 2\n",
    "\n",
    "filter_size3 = 3\n",
    "num_filters3 = 50\n",
    "strides3 = 1\n",
    "ksize_maxpool3 = 2\n",
    "\n",
    "#number of neurons\n",
    "fc_size=10\n",
    "\n",
    "#l2 regularization\n",
    "beta = 0.01\n",
    "\n",
    "tf.reset_default_graph() \n",
    "batch = None\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = (batch, img_h, img_w, num_channels),name='x')\n",
    "y = tf.placeholder(tf.int32, shape = [batch,num_labels], name='y')\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "conv1, weights1 = conv_layer(x,\n",
    "                              layer_name='conv1',layer_name_bias='conv1_b',\n",
    "                              num_input_channels=num_channels,\n",
    "                              filter_size=filter_size1,\n",
    "                              num_filters=num_filters1,\n",
    "                              strides=strides1,\n",
    "                              ksize_maxpool=ksize_maxpool1,\n",
    "                              pooling=True,\n",
    "                              batchnorm=True,\n",
    "                              dropout=False,\n",
    "                              keep_prob=keep_prob)\n",
    "\n",
    "conv2, weights2 = conv_layer(conv1,\n",
    "                              layer_name='conv2',layer_name_bias='conv2_b',\n",
    "                              num_input_channels=num_filters1,\n",
    "                              filter_size=filter_size2,\n",
    "                              num_filters=num_filters2,\n",
    "                              strides=strides2,\n",
    "                              ksize_maxpool=ksize_maxpool2,\n",
    "                              pooling=True,\n",
    "                              batchnorm=True,\n",
    "                              dropout=False,\n",
    "                              keep_prob=keep_prob)\n",
    "\n",
    "conv3, weights3 = conv_layer(conv2,\n",
    "                              layer_name='conv3',layer_name_bias='conv3_b',\n",
    "                              num_input_channels=num_filters2,\n",
    "                              filter_size=filter_size3,\n",
    "                              num_filters=num_filters3,\n",
    "                              strides=strides3,\n",
    "                              ksize_maxpool=ksize_maxpool3,\n",
    "                              pooling=True,\n",
    "                              batchnorm=True,\n",
    "                              dropout=True,\n",
    "                              keep_prob=keep_prob)\n",
    "\n",
    "conv3 = tf.reduce_mean(conv3, [1, 2], name='global_pool', keep_dims=True)\n",
    "\n",
    "flattened, num_features = flatten_layer(conv3)\n",
    "\n",
    "fc1 = fc_layer(flattened,\n",
    "               layer_name='fc1',layer_name_bias='fc1_b',\n",
    "               num_in=num_filters3,\n",
    "               num_out=fc_size,\n",
    "               relu=True,\n",
    "               batchnorm=True,\n",
    "               dropout=True,\n",
    "               keep_prob=keep_prob)\n",
    "\n",
    "fc2 = fc_layer(fc1,\n",
    "               layer_name='fc2',layer_name_bias='fc2_b',\n",
    "               num_in=fc_size,\n",
    "               num_out=num_labels,\n",
    "               relu=False,\n",
    "               batchnorm=False,\n",
    "               dropout=True,\n",
    "               keep_prob=keep_prob)\n",
    "\n",
    "y_pred = tf.nn.softmax(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Data Path: C:\\All Code\\Work\\CNN\\Prediction Data\n",
      "Pred set (1364, 300, 300, 1)\n",
      "C:\\All Code\\Work\\CNN\\Coloured_Tables_Detection\\coloured_model\\coloured_detection\n",
      "INFO:tensorflow:Restoring parameters from C:\\All Code\\Work\\CNN\\Coloured_Tables_Detection\\coloured_model\\coloured_detection\n",
      "Prediction Done! Elapsed Time: 20.69 s\n"
     ]
    }
   ],
   "source": [
    "def resize_and_create_array(filepath):\n",
    "    \n",
    "    num_files = sum([len(files) for r, d, files in os.walk(filepath)])\n",
    "    root = [root for root, folder, files in os.walk(filepath)][0]\n",
    "    X_pred = np.zeros(shape=(num_files, img_h, img_w), dtype='uint8')\n",
    "    \n",
    "    i=0\n",
    "    for root,folder,files in os.walk(filepath):\n",
    "        for file in files[:]:\n",
    "            file=file.lower()\n",
    "            path = os.path.join(root,file)\n",
    "            if '.png' not in path:\n",
    "                continue\n",
    "            try:\n",
    "                img = Image.open(path).convert('L')\n",
    "                img = np.array(img.resize((int(img_w),int(img_h))))\n",
    "                X_pred[i]=img\n",
    "                i+=1\n",
    "            except:\n",
    "                print(file)\n",
    "    \n",
    "    X_pred= np.reshape(X_pred,(-1, img_h, img_w,1))\n",
    "    X_pred = np.divide((X_pred - train_mean), train_std)\n",
    "    return X_pred\n",
    "                \n",
    "    \n",
    "def create_minibatch_pred(X,batch_size=32):\n",
    "    \n",
    "    num_training_data = X.shape[0]\n",
    "    num_of_batches = num_training_data // batch_size\n",
    "    minibatch = []\n",
    "    \n",
    "    for batch in range(num_of_batches):\n",
    "        batch_data = X[batch*batch_size:(batch+1)*batch_size, :, :, :]\n",
    "        minibatch.append(batch_data)\n",
    "    \n",
    "    if num_training_data % batch_size != 0:\n",
    "        batch_data = X[num_of_batches*batch_size:num_training_data, :, :, :]\n",
    "        minibatch.append(batch_data)\n",
    "        \n",
    "    return minibatch\n",
    "\n",
    "\n",
    "def predict_batch_2(X,batch_size=32):\n",
    "    output=[]\n",
    "    accs=0\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as session:\n",
    "        print(save_path)\n",
    "        saver.restore(session, save_path)\n",
    "        minibatches = create_minibatch_pred(X,batch_size)\n",
    "        for minibatch in minibatches:\n",
    "            batch_data = minibatch    \n",
    "            feed_dict = {x: batch_data, keep_prob: 1.0}\n",
    "            pred = session.run(y_pred, feed_dict=feed_dict)\n",
    "            pred = np.argmax(np.array(pred, copy=True),1)         \n",
    "            output.append(pred)\n",
    "            \n",
    "        output = np.array(np.concatenate(output).ravel().tolist())\n",
    "        return output\n",
    "    \n",
    "    \n",
    "def binning_pred(output):\n",
    "    files = [files for root, folder, files in os.walk(filepath)][0]\n",
    "    root = [root for root, folder, files in os.walk(filepath)][0]\n",
    "    \n",
    "    num_class = len(np.unique(output))\n",
    "    \n",
    "    i=0\n",
    "    for value in output:\n",
    "        path = os.path.join(root,files[i])\n",
    "        out_folder = 'class_'+str(value)\n",
    "        outdir = os.path.join(root,out_folder)\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "        shutil.copy(path,outdir)\n",
    "        i+=1\n",
    "            \n",
    "def main_predict():\n",
    "    start_time = time.time()\n",
    "    X_pred = resize_and_create_array(filepath)\n",
    "    print('Pred set', X_pred.shape)\n",
    "    output = predict_batch_2(X_pred)\n",
    "    binning_pred(output)\n",
    "    time_diff = time.time() - start_time\n",
    "    print('Prediction Done! Elapsed Time: %.2f s' %time_diff)\n",
    "\n",
    "save_dir = r'C:\\All Code\\Work\\CNN\\Coloured_Tables_Detection\\coloured_model'\n",
    "save_path = os.path.join(save_dir, 'coloured_detection')\n",
    "\n",
    "filepath = input(\"Prediction Data Path: \")\n",
    "main_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
